{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in AGRadGalNet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "\n",
    "import configparser as ConfigParser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "from networks import AGRadGalNet\n",
    "from datasets import MiraBest_full, MBFRConfident, MBFRUncertain, MBHybrid\n",
    "\n",
    "# Set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Read in config file\n",
    "config_name = \"configs/template.cfg\"\n",
    "config = ConfigParser.ConfigParser(allow_no_value=True)\n",
    "config.read(config_name)\n",
    "\n",
    "# Load network architecture (with random weights)\n",
    "print(f\"Loading in {config['model']['base']}\")\n",
    "net = locals()[config['model']['base']](**config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create data transformations\n",
    "datamean = config.getfloat('data', 'datamean')\n",
    "datastd = config.getfloat('data', 'datastd')\n",
    "number_rotations = config.getint('data', 'number_rotations')\n",
    "imsize = config.getint('data', 'imsize')\n",
    "scaling_factor = config.getfloat('data', 'scaling')\n",
    "angles = list(range(0, 360, config.getint('data', 'number_rotations')))\n",
    "p_flip = 0.5 if config.getboolean('data','flip') else 0\n",
    "\n",
    "# Create hard random (seeded) rotation:\n",
    "class RotationTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "    def __init__(self, angles, resample):\n",
    "        self.angles = angles\n",
    "        self.resample = resample\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = np.random.choice(a=self.angles, size=1)\n",
    "        return transforms.functional.rotate(x, angle, resample=self.resample)\n",
    "\n",
    "\n",
    "# Compose dict of transformations\n",
    "transformations = {\n",
    "    'none': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([datamean],[datastd])\n",
    "    ]),\n",
    "    'rotation and flipping': transforms.Compose([\n",
    "        transforms.CenterCrop(imsize),\n",
    "        transforms.RandomVerticalFlip(p=p_flip),\n",
    "        RotationTransform(angles, resample=PIL.Image.BILINEAR),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0, # No uncontrolled rotation\n",
    "            scale=(1-scaling_factor, 1+scaling_factor), \n",
    "            resample=PIL.Image.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([datamean],[datastd])\n",
    "    ]),\n",
    "    'no rotation no flipping': transforms.Compose([\n",
    "        transforms.CenterCrop(imsize),\n",
    "        transforms.RandomVerticalFlip(p=p_flip),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0, # No uncontrolled rotation\n",
    "            scale=(1-scaling_factor, 1+scaling_factor), \n",
    "            resample=PIL.Image.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([datamean],[datastd])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Read / Create Folder for Data to be Saved\n",
    "root = config['data']['directory']\n",
    "if not os.path.isdir(root):\n",
    "    os.mkdir(root)\n",
    "download = True\n",
    "train = True\n",
    "data_class = locals()[config['data']['dataset']]\n",
    "data_set = data_class(root=root, download=download, train=train, transform=transformations['rotation and flipping'])\n",
    "\n",
    "# Seperate Data into Subsets for Training, Validation, Testing.\n",
    "traindata = data_class(root=root, download=download, train=True, transform=transformations['rotation and flipping'])\n",
    "testdata = data_class(root=root, download=download, train=False, transform=transformations['rotation and flipping'])\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(traindata, batch_size=config.getint('training', 'batch_size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099\n",
      "[tensor([[[[-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          ...,\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886]]],\n",
      "\n",
      "\n",
      "        [[[-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          ...,\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886]]],\n",
      "\n",
      "\n",
      "        [[[-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          ...,\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          ...,\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886]]],\n",
      "\n",
      "\n",
      "        [[[-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          ...,\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886]]],\n",
      "\n",
      "\n",
      "        [[[-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          ...,\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886],\n",
      "          [-0.0886, -0.0886, -0.0886,  ..., -0.0886, -0.0886, -0.0886]]]]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      "(1099, 150, 150, 1)\n",
      "1099\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2025000 into shape (150,150)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2906d417785e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/datasets/MiraBest.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2025000 into shape (150,150)"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for data, label in traindata:\n",
    "    count+=1\n",
    "print(count)\n",
    "\n",
    "for d in trainset:\n",
    "    print(d)\n",
    "    break\n",
    "    \n",
    "print(traindata.data.shape)\n",
    "print(len(traindata.targets))\n",
    "print(traindata[10:100][0].shape)\n",
    "plt.imshow(traindata[0][0].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counter = 0\n",
    "for data, label in traindata:\n",
    "    counter+=1\n",
    "    plt.imshow(np.asarray(data)[0])\n",
    "    plt.title(['FRI','FRII'][label])\n",
    "    plt.show()\n",
    "    if counter>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rate = config.getfloat('training', 'learning_rate')\n",
    "optimizers = {\n",
    "    'SGD': optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9),\n",
    "    'Adagrad': optim.Adagrad(net.parameters(), lr=learning_rate),\n",
    "    'Adadelta': optim.Adadelta(net.parameters(), lr=learning_rate),\n",
    "    'Adam': optim.Adam(net.parameters(), lr=learning_rate)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Model:\n",
    "    def __init__(self, configfile):\n",
    "        # Read in the config file\n",
    "        self.config_name = configfile\n",
    "        self.config = ConfigParser.SafeConfigParser(allow_no_value=True)\n",
    "        self.config.read(self.config_name)\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.net = utils.net.load(\n",
    "            device=self.device, \n",
    "            **self.config['model'])\n",
    "        self.data = utils.data.load(\n",
    "            device=self.device, \n",
    "            rotations=self.config.getint('model', 'number_rotations'), \n",
    "            **self.config['data'])\n",
    "        self.train = utils.train.load(self.config_name)\n",
    "        \n",
    "        self.model_trained = self.config.getboolean('grid_search', 'done')\n",
    "        \n",
    "\n",
    "    def model_trained(self):\n",
    "        if self.config.getboolean('grid_search', 'done'):\n",
    "            print('Training not required')\n",
    "        else:\n",
    "            print('Training required')\n",
    "\n",
    "test_net = Model('configs/template.cfg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Data Manipulation:\n",
    "- path_to_model(file_name)\n",
    "- data_call(dataset_name)\n",
    "- determine_dataset(dataset,model_name) ... dataset in ['automatic','FRDEEP-F','MiraBest']\n",
    "\n",
    "Model Manipulation:\n",
    "- load_net(model_name,device)\n",
    "- training_validation(PATH,xlims=[None,None],save=False,full_path=False) ... PATH is a local title of a folder or file (within ./TrainedNetworks)\n",
    "- prediction(dataset, net, class_groups,(device='cuda',reps='360'))\n",
    "- evaluate(file_name, dataset='automatic')\n",
    "\n",
    "Evaluation Plots:\n",
    "- plot_conf_mat(conf_matrix,normalised=True,n_classes=2,format_input=None,title='Confusion Matrix')\n",
    "- plot_roc_curve(fpr,tpr,title='ROC Curve (AUC=\\{auc:.3f\\})')\n",
    "- out_print(out)\n",
    "\n",
    "Attention Maps:\n",
    "- attentions_func(batch_of_images, net, mean=True, device=torch.device('cpu'))\n",
    "- attention_analysis(source, source_only=True, attention_maps=None, GradCAM=None)\n",
    "- AttentionImagesByEpoch(sources, folder_name, net,epoch=1500, device=torch.device('cpu'))\n",
    "- attention_epoch_plot(source_images,folder_name, logged=False, width=3, device=torch.device('cpu'))\n",
    "\n",
    "GradCAM:\n",
    "- To be completed.\n",
    "\n",
    "Other:\n",
    "- mask_on_image(img, mask)\n",
    "- SortedDataSamples(data_name, transformed=True,  rotations=1, subset='NOHYBRID')\n",
    "- net_name_extraction(PATH)\n",
    "\n",
    "Incomplete:\n",
    "- Loading from Pickled dicts\n",
    "- GradCAM Call for a given image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr = model.config['grid_search']['learning_rate'].split(',')[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load in config\n",
    "config_path = f\"configs/template.cfg\"\n",
    "config = configparser.ConfigParser()\n",
    "config.red(config_path)\n",
    "\n",
    "#Â Select model according to config\n",
    "#net = load_model(config['model']['name'])\n",
    "\n",
    "# Select data\n",
    "#data = select_data(config['data']['name'])\n",
    "\n",
    "# Grid Search\n",
    "#hyperparams = grid_search(net, data, **config['training'])\n",
    "\n",
    "# Retrain with Best Hyperparameters\n",
    "#model = final_train(net, data, net)\n",
    "\n",
    "# Evaluate Model\n",
    "\n",
    "\n",
    "# Generate Plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "config_path = f\"configs/template.cfg\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_path)\n",
    "print(config.sections())\n",
    "print(*config['model'])\n",
    "print(config['model']['base'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datasets.FRDEEP()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def test(base, nrot, early_stopping, quiet):\n",
    "    return None\n",
    "test(**config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
